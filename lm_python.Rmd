---
title: "lm en python"
author: "FinistR"
date: "26/08/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Python depuis `rstudio`

On peut appeler python en `r` grâce au package `reticulate`

```{r lm_python_library_reticulate}
library(reticulate)
```

# Objectif

Le but de ce tutoriel est de faire un TP de modèle linéaire en python, en retrouvant tout les sorties de la fonction `lm` usuelle

# Importation des données

On utilisera la library de python `pandas` pour importer les données.
Pour l'installer depuis `R`, on utilise la fonction 

```{r py_install_pandas}
# Run only once
# py_install("pandas")
# py_install("numpy")
# py_install("scikit-learn")
#py_install("seaborn")
# py_install("statsmodels")
```

Ensuite, on importe la librairie, et on charge les données, à la manière de `read.table`.

```{python}
import pandas
bats = pandas.read_csv("bats.csv", # Nom du fichier 
                          sep = ";", # Separateur de champs
                          skiprows = 3, # On ignore les 3 premieres lignes 
                          header = 0) # La premiere ligne correspond au nom de colonnes
print(bats)        
```

# Selection logique

Pour extraire une sous partie des données, on peut utiliser la sélection par un vecteur logique.

```{python}
# bats.Diet recupere la colonne Diet dans bats
condition_phyto = bats.Diet == 1 # Une colonne de condition
condition_BOW = bats.BOW < 400 # Outlier
batsphyto = bats[condition_phyto & condition_BOW]
batsphyto
```

# Avec `scikit-learn`

Pour ajuster une regression linéaire, on peut utiliser la librairie

```{python}
import numpy as np
import sklearn.linear_model as sklm

# Les features ("X") doivent être données sous forme de matrice
X = np.asarray(batsphyto.BOW).reshape(-1, 1)
regression_simple = sklm.LinearRegression()
regression_simple.fit(X = X, y = batsphyto.BRW)

# beta0
beta0, beta1 = [regression_simple.intercept_, regression_simple.coef_]
beta0, beta1
```

```{python regression, message = FALSE, results = "hide"}
import statsmodels.api as sm_api
import statsmodels.formula.api as sm_formula
from statsmodels.sandbox.regression.predstd import wls_prediction_std
import matplotlib.pyplot as plt
regression = sm_formula.ols("BRW ~ BOW", data = batsphyto).fit()
print(regression.summary())
```


On peut representer graphiquement la droite de regression ainsi que les intervalles de confiance associés

```{python wls_prediction_std(regression)}
# Calcul 
fig = sm_api.graphics.plot_fit(regression, "BOW")
plt.show()
```

# Graphiques des résidus

On accède aux résidus avec les différents attributs de l'objet `regression`.

```{python}
plt.close()
plot_residus = plt.plot(regression.fittedvalues, regression.resid, "o")
plt.show()
```

# Graphique de l'influence

On peut obtenir le vecteur des distances de Cook grâce à la méthode `get_influence`

```{python statsmodel_cooks_distance}
distances_cook = regression.get_influence().cooks_distance[0]
```

On peut tracer résidus standardisés en fonction du levier grâce à une fonction dédiée, graphique sans légende...

```{python}
fig = sm_api.graphics.influence_plot(regression, criterion="cooks", alpha = 0.005)
regression.get_influence().cooks_distance
plt.show()
```

# Tests sur les paramètres

On peut tester si une combinaison linéaire des paramètres est égale à 0:

```{python}
combinaisons_lineaires = "Intercept = 0, BOW = 0, BOW - Intercept = 0, 3 * Intercept = 2 * BOW"
print(regression.t_test(combinaisons_lineaires))
```

# Tests sur les modèles emboités

```{python}
from statsmodels.stats.anova import anova_lm
regression_multiple = sm_formula.ols('BRW ~ BOW + AUD', data = batsphyto).fit()
anovaResults = anova_lm(regression_multiple, typ = "II") # On peut choisir le type
print(anovaResults)
```

# ANCOVA

Il semblerait que l'inclusion des variables qualitatives se déroule de la même manière que dans `R`.
Exemple sur l'ANCOVA:

```{python}
ancova = sm_formula.ols('BRW ~ Clade * BOW', data = batsphyto).fit()
print(ancova.summary())
```

# Moyennes ajustées

Il semblerait que, pour le moment, le calcul des moyennes ajustées doivent se faire à la main!







